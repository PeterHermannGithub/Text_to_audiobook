# Text-to-Audiobook Production Docker Compose
# Optimized for production deployment with security and performance

version: '3.8'

services:
  # Main application service
  app:
    build:
      context: ..
      dockerfile: docker/Dockerfile
    container_name: text_to_audiobook_app_prod
    environment:
      - PYTHONPATH=/app
      - LOG_LEVEL=INFO
      - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
      - REDIS_URL=redis://redis:6379/0
      - SPARK_MASTER=spark://spark:7077
      - PROMETHEUS_PORT=8000
    ports:
      - "8000:8000"
    volumes:
      - ../input:/app/input:ro
      - ../output:/app/output
      - ../logs:/app/logs
    depends_on:
      - kafka
      - redis
      - spark
    networks:
      - textapp-prod-network
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 4G
          cpus: '2'
        reservations:
          memory: 2G
          cpus: '1'
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # Load balancer for high availability
  nginx:
    image: nginx:alpine
    container_name: text_to_audiobook_nginx_prod
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
      - ./ssl:/etc/nginx/ssl:ro
    depends_on:
      - app
    networks:
      - textapp-prod-network
    restart: unless-stopped

  # Apache Kafka for event streaming
  kafka:
    image: confluentinc/cp-kafka:7.4.0
    container_name: text_to_audiobook_kafka_prod
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_HEAP_OPTS: "-Xmx2G -Xms2G"
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "false"
    ports:
      - "9092:9092"
    depends_on:
      - zookeeper
    networks:
      - textapp-prod-network
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 3G
          cpus: '1'
        reservations:
          memory: 2G
          cpus: '0.5'

  # Zookeeper for Kafka coordination
  zookeeper:
    image: confluentinc/cp-zookeeper:7.4.0
    container_name: text_to_audiobook_zookeeper_prod
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      ZOOKEEPER_HEAP_OPTS: "-Xmx1G -Xms1G"
    ports:
      - "2181:2181"
    networks:
      - textapp-prod-network
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 1.5G
          cpus: '0.5'

  # Redis for caching and session management
  redis:
    image: redis:7-alpine
    container_name: text_to_audiobook_redis_prod
    ports:
      - "6379:6379"
    command: redis-server --appendonly yes --requirepass ${REDIS_PASSWORD:-defaultpass}
    volumes:
      - redis-prod-data:/data
    networks:
      - textapp-prod-network
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '0.5'

  # Apache Spark master
  spark:
    image: bitnami/spark:3.4
    container_name: text_to_audiobook_spark_master_prod
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - SPARK_MASTER_OPTS="-Dspark.deploy.defaultCores=2"
    ports:
      - "7077:7077"
      - "8080:8080"
    networks:
      - textapp-prod-network
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '1'

  # Apache Spark worker
  spark-worker:
    image: bitnami/spark:3.4
    container_name: text_to_audiobook_spark_worker_prod
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark:7077
      - SPARK_WORKER_MEMORY=4G
      - SPARK_WORKER_CORES=2
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    depends_on:
      - spark
    networks:
      - textapp-prod-network
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 5G
          cpus: '2'
      replicas: 2

  # Prometheus for metrics collection
  prometheus:
    image: prom/prometheus:latest
    container_name: text_to_audiobook_prometheus_prod
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus-prod-data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=30d'
      - '--web.enable-lifecycle'
    networks:
      - textapp-prod-network
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '1'

  # Grafana for monitoring dashboards
  grafana:
    image: grafana/grafana:latest
    container_name: text_to_audiobook_grafana_prod
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD:-admin}
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_SECURITY_DISABLE_GRAVATAR=true
      - GF_ANALYTICS_REPORTING_ENABLED=false
      - GF_ANALYTICS_CHECK_FOR_UPDATES=false
    volumes:
      - grafana-prod-data:/var/lib/grafana
      - ./grafana-provisioning:/etc/grafana/provisioning:ro
    depends_on:
      - prometheus
    networks:
      - textapp-prod-network
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '0.5'

  # Log aggregation with Fluentd
  fluentd:
    image: fluent/fluentd:v1.16-debian-1
    container_name: text_to_audiobook_fluentd_prod
    volumes:
      - ./fluentd.conf:/fluentd/etc/fluent.conf:ro
      - ../logs:/var/log/textapp:ro
    depends_on:
      - elasticsearch
    networks:
      - textapp-prod-network
    restart: unless-stopped

  # Elasticsearch for log storage
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.8.0
    container_name: text_to_audiobook_elasticsearch_prod
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - "ES_JAVA_OPTS=-Xms1g -Xmx1g"
    volumes:
      - elasticsearch-prod-data:/usr/share/elasticsearch/data
    networks:
      - textapp-prod-network
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '1'

  # Kibana for log visualization
  kibana:
    image: docker.elastic.co/kibana/kibana:8.8.0
    container_name: text_to_audiobook_kibana_prod
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    ports:
      - "5601:5601"
    depends_on:
      - elasticsearch
    networks:
      - textapp-prod-network
    restart: unless-stopped

volumes:
  redis-prod-data:
  prometheus-prod-data:
  grafana-prod-data:
  elasticsearch-prod-data:

networks:
  textapp-prod-network:
    driver: bridge